{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0e838e-3e8c-429d-885e-7d079a1d8ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\bikki\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\bikki\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\bikki\\anaconda3\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install dependencies\n",
    "!pip install openai faiss-cpu pandas numpy --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cfd0a0-8df0-40a5-bbbe-d7a64c12fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load your chunks\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"heading_sliding_chunks.csv\")  # url, section, chunk_id, text\n",
    "texts = df[\"text\"].tolist()\n",
    "total = len(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2922ae4-6ea0-47ea-9b29-96538d88d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Initialize OpenAI client\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "client = OpenAI(api_key=\"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\")  # ← replace with your key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf8326b6-f9a7-430f-ab98-8c468e5799ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 8000/48901 embeddings\n",
      "✅ Processed 16000/48901 embeddings\n",
      "✅ Processed 24000/48901 embeddings\n",
      "✅ Processed 32000/48901 embeddings\n",
      "✅ Processed 40000/48901 embeddings\n",
      "✅ Processed 48000/48901 embeddings\n",
      "✅ Processed 48901/48901 embeddings\n",
      "✅ All embeddings saved.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Embed in batches with progress\n",
    "batch_size = 64\n",
    "embeddings = []\n",
    "processed = 0\n",
    "\n",
    "for i in range(0, total, batch_size):\n",
    "    batch = texts[i : i + batch_size]\n",
    "    resp = client.embeddings.create(\n",
    "        input=batch,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    embeddings.extend([np.array(d.embedding) for d in resp.data])\n",
    "    processed += len(batch)\n",
    "    if processed % 2000 == 0 or processed == total:\n",
    "        print(f\"✅ Processed {processed}/{total} embeddings\")\n",
    "\n",
    "df[\"embedding\"] = embeddings\n",
    "df.to_pickle(\"chunks_with_openai_embeddings.pkl\")\n",
    "print(\"✅ All embeddings saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3cbd4d4-5614-443e-9a17-9221a959bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index built with 48901 vectors.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Build FAISS index\n",
    "import faiss\n",
    "\n",
    "# Normalize helper\n",
    "def normalize(v): return v / np.linalg.norm(v)\n",
    "\n",
    "emb_matrix = np.stack(df[\"embedding\"].apply(normalize).values)\n",
    "d = emb_matrix.shape[1]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(emb_matrix)\n",
    "print(f\"✅ FAISS index built with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55c7e324-c843-4292-8133-5a76afbfa055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students enrolling in the MS Business Analytics and Artificial Intelligence Cohort or MS Business Analytics and Artificial Intelligence Cohort Online programs at the University of Texas at Dallas are not eligible for the Dean’s Excellence Scholarship. These students should visit their program webpages or director for specific scholarship opportunities associated with those programs.\n",
      "[{'url': 'https://jindal.utdallas.edu/consortium-online-graduate-business-education/founding-schools', 'section': 'North Carolina State University – Poole College of Management', 'text': 'Assistant Dean of Graduate Programs'}, {'url': 'https://jindal.utdallas.edu/consortium-online-graduate-business-education/founding-schools', 'section': 'Arizona State University – WP Carey School of Business', 'text': 'Assistant Dean of Graduate Programs'}, {'url': 'https://jindal.utdallas.edu/blog/jsom-jump-starts-fall-2023', 'section': 'Food, Fun and Friends', 'text': 'undergraduate dean.'}, {'url': 'https://jindal.utdallas.edu/faq/ms-business-analytics-faq/how-can-i-get-a-scholarship-assistantship', 'section': 'How can I get a scholarship/assistantship?', 'text': 'Students enrolling in the MS Business Analytics and Artificial Intelligence Cohort or MS Business Analytics and Artificial Intelligence Cohort Online programs are not eligible for the Dean’s Excellence Scholarship. These students should visit their program webpages or director for specific scholarship opportunities associated with those programs. A few graduate assistantships are also awarded at the discretion of the JSOMInformation Systems Area. Learn more on theGraduate Assistantshipspage.'}, {'url': 'https://jindal.utdallas.edu/fintech-digital-assets-workshop-2023-comtech', 'section': 'Workshop Chairs', 'text': 'Assitant Dean, Graduate Programs'}]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Retrieval + RAG answer function\n",
    "def retrieve_chunks(query, k=5):\n",
    "    qv = normalize(np.array(client.embeddings.create(\n",
    "        input=[query], model=\"text-embedding-ada-002\"\n",
    "    ).data[0].embedding))\n",
    "    D, I = index.search(np.array([qv]), k)\n",
    "    return df.iloc[I[0]][[\"url\",\"section\",\"text\"]].to_dict(\"records\")\n",
    "\n",
    "def generate_answer(query):\n",
    "    top = retrieve_chunks(query)\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"{c['text']}\\n(Source: {c['url']}, Section: {c['section']})\"\n",
    "        for c in top\n",
    "    )\n",
    "    prompt = (\n",
    "        \"You are a helpful UTD chatbot.\\n\\n\"\n",
    "        \"Use the context below to answer the question. If listing items, format them as bullet points.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question:\\n{query}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "top = retrieve_chunks(\"Deans Excellence Scholarship\")\n",
    "# Test it\n",
    "print(generate_answer(\"Deans Excellence Scholarship?\"))\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f509af-9ee9-41dd-9eb0-a923d6eb07e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
